{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 4: Convolución y filtros**\n",
    "\n",
    "<img src =\"https://epigijon.uniovi.es/image/image_gallery?uuid=903ae5c8-b29b-430e-980d-1a19a885c736&groupId=3743853&t=1688576582973\" width=300 px>\n",
    "\n",
    "Este cuaderno desarrolla contenidos prácticos de la asignatura **Visión artificial** del Grado en Ciencia e Ingeniería de Datos.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolución\n",
    "\n",
    "La operación de convolución es un concepto fundamental en el campo del procesamiento de señales e imágenes, incluyendo el aprendizaje profundo. La convolución es por tanto una herramienta esencial en diversas disciplinas, desde el procesamiento de imágenes hasta la inteligencia artificial.\n",
    "\n",
    "La convolución es un proceso que combina dos funciones para crear una tercera que representa cómo una de las funciones modifica la otra. En el contexto del procesamiento de señales, la convolución se utiliza para analizar cómo una señal responde a otra, y en el ámbito de la visión por computador y las redes neuronales convolucionales, la operación de convolución se aplica para extraer características clave de las imágenes.\n",
    "\n",
    "La convolución es una operación fundamental en la identificación de patrones, detección de características relevantes y reducción de la dimensionalidad de datos, lo cual es crucial para el éxito de muchas aplicaciones modernas, como reconocimiento de objetos, segmentación de imágenes y procesamiento de lenguaje natural. Comprender los principios detrás de la operación de convolución es esencial para aquellos involucrados en campos como la informática, la ingeniería de señales y la inteligencia artificial, ya que sienta las bases para abordar problemas complejos y aprovechar al máximo las capacidades de los modelos computacionales.\n",
    "\n",
    "Matemáticamente la convolución se define como:\n",
    "\n",
    "$\n",
    "g(x) = f(x) * h(x) = \\int_{-\\infty}^{\\infty} f(\\tau) \\cdot h(x - \\tau) \\, d \\tau\n",
    "$\n",
    "\n",
    "que de forma discreta se corresponde con\n",
    "\n",
    "$\n",
    "g[i] = (f * h)[i] = \\sum_{n = 0}^{N -1} f[n] \\cdot h[i - n]\n",
    "$\n",
    "\n",
    "De forma práctica se implementaría tal y como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  7 10 22 31 43 20]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "f = (1, 2, 0, 7, 5)\n",
    "h = (2, 3, 4)\n",
    "\n",
    "g = np.convolve(f, h)\n",
    "\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se rellenan los bordes con ceros. En caso de solamente necesitar aquella parte válida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 22, 31])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.convolve(f, h, mode=\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación rellenando con ceros sería similar a la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  7., 10., 22., 31., 43., 20.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convolution(f, h):\n",
    "    # Tamaño de las señales\n",
    "    M = len(f)\n",
    "    N = len(h)\n",
    "\n",
    "    # Tamaño de la señal resultante\n",
    "    conv = np.zeros(M + N - 1)\n",
    "\n",
    "    for i in range(M + N - 1):\n",
    "        for k in range(max(0, i - N + 1), min(M, i + 1)):\n",
    "            conv[i] += f[k] * h[i - k]\n",
    "\n",
    "    return conv\n",
    "\n",
    "convolution(f, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza el código anterior e intenta comprender su funcionamiento. \n",
    "\n",
    "Otra forma de verlo sería con el código siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_zeros: [0. 0. 1. 2. 0. 7. 5. 0. 0.]\n",
      "h_reversed: [4 3 2]\n",
      "g[0] = 2.0\n",
      "g[1] = 7.0\n",
      "g[2] = 10.0\n",
      "g[3] = 22.0\n",
      "g[4] = 31.0\n",
      "g[5] = 43.0\n",
      "g[6] = 20.0\n"
     ]
    }
   ],
   "source": [
    "len_h = len(h)\n",
    "fill_len = len(h)-1\n",
    "                    \n",
    "f_zeros = np.concatenate([np.zeros(fill_len), f, np.zeros(fill_len)])\n",
    "print(f\"f_zeros: {f_zeros}\")\n",
    "\n",
    "h_reversed = np.flip(h)\n",
    "print(f\"h_reversed: {h_reversed}\")\n",
    "\n",
    "for i in range(0, len(f_zeros) - fill_len):\n",
    "    acum = 0\n",
    "    for j in range(0, len(h)):\n",
    "        acum += f_zeros[i+j] * h_reversed[j]\n",
    "\n",
    "    print(f\"g[{i}] = {acum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convolución en el dominio bidimensional (2D) es una extensión natural de la convolución en el dominio unidimensional (1D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_2d(image, kernel):\n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    # Obtener las dimensiones de la imagen y el kernel\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # Calcular las dimensiones del resultado de la convolución (parte válida)\n",
    "    output_height = image_height - kernel_height + 1\n",
    "    output_width = image_width - kernel_width + 1\n",
    "\n",
    "    # Inicializar la matriz de salida\n",
    "    output = np.zeros((output_height, output_width))\n",
    "\n",
    "    # Realizar la convolución\n",
    "    for y in range(output_height):\n",
    "        for x in range(output_width):\n",
    "            output[y, x] = np.sum(image[y:y+kernel_height, x:x+kernel_width] * kernel)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = skimage.data.chelsea()\n",
    "cat_gray = skimage.color.rgb2gray(cat)\n",
    "plt.imshow(cat_gray, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "kernel = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "cat_edges = convolution_2d(cat_gray, kernel)\n",
    "plt.imshow(cat_edges, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `skimage.color.rgb2gray` convierte la imagen a flotante en escala [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_gray.dtype)\n",
    "plt.imshow(cat_gray, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El kernel utilizado sirve para calcular los bordes en sentido vertical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede verificar que el resultado coincide con la función de la biblioteca scipy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_edges_scipy = scipy.signal.convolve2d(cat_gray, kernel, mode=\"valid\")\n",
    "np.allclose(cat_edges, cat_edges_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suavizado\n",
    "\n",
    "> Realiza la convolución para obtener una versión suavizada de la imagen, donde cada píxel se sustituya por la medida en una vecindad de tamaño 15x15. Recuerda normalizar el kernel (que la suma de sus elementos sea 1) para no alterar el brillo de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El suavizado con una función gaussiana sería similar y se puede realizar directamente con una función de biblioteca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desviación estándar de la distribución Gaussiana\n",
    "sigma = 5 \n",
    "\n",
    "# Calcula la convolución de la imagen con un kernel Gaussiano\n",
    "cat_blur = scipy.ndimage.gaussian_filter(cat_gray, (sigma,sigma))\n",
    "plt.imshow(cat_gray, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(cat_blur, cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afilado\n",
    "\n",
    "El afilado, o sharpening en inglés, es un proceso utilizado en el procesamiento de imágenes para resaltar los bordes y mejorar la nitidez aparente de los detalles. Este procedimiento busca realzar los contrastes locales en una imagen, haciendo que los límites entre regiones sean más distintivos.\n",
    "\n",
    "Una de las opciones es el llamado algoritmo Unsharp masking, que consisten en realizar la siguiente operación sobre una imagen:\n",
    "\n",
    "sharpened = original + (original − blurred) × amount\n",
    "\n",
    "> Implementa esta operación sobre la imagen `http://www.atc.uniovi.es/grado/3va/prac/eye.png`\n",
    "\n",
    "> Para cada canal de la imagen en color...\n",
    ">\n",
    "> Realiza una conversión a formato real en el rango [0, 1] (división del canal entre 255.0)\n",
    ">\n",
    "> Aplica `scipy.ndimage.gaussian_filter` sobre el resultado con sigma valor 5\n",
    ">\n",
    "> Realiza la operación `channel + (channel - blur) * strength` con strength valor 1.5. Se debe evitar que el resultado se salga del rango de representación.\n",
    ">\n",
    "> Devuelve el canal al rango [0, 255] (multiplicación por 255) y convierte a `np.uint8`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operación anterior se podría aproximar usando un kernel similar al siguiente:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 5 & -1 \\\\\n",
    "0 & -1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "> Realiza el afilado de la imagen usando ese kernel y la función `convolution_2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente\n",
    "\n",
    "La misma función permite calcular la convolución con el operador FDoG (derivada de la Gaussiana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3 # standard deviation\n",
    "\n",
    "# Calcula la convolución de la imagen con la derivada del kernel Gaussiano en x\n",
    "imx = scipy.ndimage.gaussian_filter(cat_gray, (sigma,sigma), (0,1))\n",
    "# Calcula la convolución de la imagen con la derivada del kernel Gaussiano en y\n",
    "imy = scipy.ndimage.gaussian_filter(cat_gray, (sigma,sigma), (1,0))\n",
    "# Calcula la magnitud del gradiente\n",
    "magnitude = np.sqrt(imx**2+imy**2)\n",
    "\n",
    "# muestra el gradiente en x e y, y la magnitud del gradiente\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(imx, cmap=\"gray\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(imy, cmap=\"gray\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(np.sqrt(imx**2+imy**2), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplaciano\n",
    "\n",
    "El operador Laplaciano es un operador diferencial utilizado en el procesamiento de imágenes para resaltar las regiones donde la intensidad varía rápidamente, como los bordes. Este operador es especialmente útil para detectar discontinuidades en una imagen.\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & -4 & 1 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Este kernel suma los valores de los píxeles vecinos y resta 4 veces el valor del píxel central, dando como resultado la segunda derivada de la intensidad de la imagen. Esta operación resalta las regiones donde la intensidad varía rápidamente, lo que suele ocurrir en los bordes de los objetos en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 3 # standard deviation\n",
    "result = scipy.ndimage.gaussian_laplace(cat_gray, (sigma,sigma))\n",
    "plt.imshow(result, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imágenes híbridas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El filtrado paso bajo y el filtrado paso alto son técnicas comunes en procesamiento de imágenes utilizadas para resaltar o atenuar diferentes componentes de la imagen en función de sus frecuencias. \n",
    "\n",
    "El filtrado paso bajo se refiere a la técnica de resaltar las componentes de baja frecuencia de una imagen y atenuar o eliminar las componentes de alta frecuencia. Esto se logra mediante el uso de un filtro que deja pasar las frecuencias bajas y atenúa las frecuencias altas. En este caso se aplica una operación de convolución entre la imagen original y el núcleo (kernel) del filtro paso bajo, comúnmente un filtro gaussiano. La convolución da como resultado una nueva imagen donde las frecuencias altas han sido atenuadas, resaltando así las características de baja frecuencia. El filtrado paso bajo es utilizado para suavizar la imagen, eliminando detalles finos o ruido.\n",
    "\n",
    "El filtrado paso alto, por otro lado, resalta las componentes de alta frecuencia de una imagen mientras atenúa las componentes de baja frecuencia. El filtro más comúnmente utilizado para el filtrado paso alto es el filtro de realce de bordes, como el filtro Laplaciano. Se aplica una operación de convolución entre la imagen original y el kernel del filtro paso alto, como el filtro Laplaciano. La convolución da como resultado una nueva imagen donde las frecuencias bajas (detalles grandes y suaves) han sido atenuadas, destacando así las características de alta frecuencia, como bordes y detalles finos. El filtrado paso alto es utilizado para resaltar los bordes y detalles finos en una imagen. También se usa para la detección de características, donde puede ser utilizado para detectar características específicas en una imagen.\n",
    "\n",
    "Ambas técnicas, filtrado paso bajo y paso alto, se utilizan en conjunto en la creación de [imágenes híbridas](https://en.wikipedia.org/wiki/Hybrid_image), donde la imagen final combina las características de baja y alta frecuencia de dos imágenes diferentes. La idea principal es que al ver la imagen de cerca, predominen las características de alta frecuencia, mientras que al verla desde lejos, predominen las características de baja frecuencia.\n",
    "\n",
    "> Busca dos imágenes que desees combinar y asegúrate de que tengan el mismo tamaño. Esto es crucial para garantizar una combinación adecuada.\n",
    "\n",
    "> Realiza una alineación manual de las dos imágenes. Puedes utilizar software de edición de imágenes para superponerlas y ajustar la posición y la rotación hasta que estén alineadas de manera satisfactoria. Es importante que las características clave en ambas imágenes coincidan.\n",
    ">\n",
    "> Convierte ambas imágenes a escala de grises si no lo están.\n",
    "\n",
    "> Aplica un filtro paso bajo (por ejemplo, un filtro gaussiano) a una de las imágenes para obtener la versión de baja frecuencia. Puedes usar la función `gaussian_filter` de la biblioteca `scipy.ndimage`.\n",
    "\n",
    "> Aplica un filtro paso alto a la otra.\n",
    "\n",
    "> Suma la imagen de baja frecuencia con la imagen de alta frecuencia. Asegúrate de que los valores de los píxeles estén en el rango adecuado (por ejemplo, 0 a 255).\n",
    "\n",
    "> Visualiza ambas imágenes desde cerca y desde lejos. Al ver la imagen desde cerca, deberías notar principalmente las características de alta frecuencia (detalles finos, bordes). Al ver la imagen desde lejos, deberías notar principalmente las características de baja frecuencia (formas generales, suavizado).\n",
    "\n",
    "> Ajusta la intensidad del filtrado paso bajo y alto según tus preferencias para lograr el efecto deseado. Experimenta con diferentes pares de imágenes para obtener resultados interesantes.\n",
    "\n",
    "Recuerda que el éxito de la creación de imágenes híbridas a menudo depende de la elección de las imágenes de partida y de cómo se ajustan los parámetros de filtrado.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
